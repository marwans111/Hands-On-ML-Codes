import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer

# Load the dataset
housing = pd.read_csv("housing.csv")

# Train/Test Split
train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)

# Data Cleaning
housing_num = housing.drop("ocean_proximity", axis=1)
imputer = SimpleImputer(strategy="median")
housing_num_imputed = imputer.fit_transform(housing_num)

# Feature Scaling
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('scaler', StandardScaler())
])

# Full Pipeline
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, housing_num.columns)
])

housing_prepared = full_pipeline.fit_transform(housing)
